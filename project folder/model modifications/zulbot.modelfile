# Modelfile generated by "ollama show"
# To build a new Modelfile based on this, replace FROM with:
# FROM qwen3:8b

FROM C:\Users\htsocadmin\.ollama\models\blobs\sha256-a3de86cd1c132c822487ededd47a324c50491393e6565cd14bafa40d0b8e686f
TEMPLATE """{{- if .Messages }}
{{- if or .System .Tools }}<|im_start|>system
{{- if .System }}
{{ .System }}
{{- end }}
{{- if .Tools }}

# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{{- range .Tools }}
{"type": "function", "function": {{ .Function }}}
{{- end }}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call>
{{- end }}<|im_end|>
{{ end }}
{{- range $i, $_ := .Messages }}
{{- $last := eq (len (slice $.Messages $i)) 1 -}}
{{- if eq .Role "user" }}<|im_start|>user
{{ .Content }}<|im_end|>
{{ else if eq .Role "assistant" }}<|im_start|>assistant
{{ if .Content }}{{ .Content }}
{{- else if .ToolCalls }}<tool_call>
{{ range .ToolCalls }}{"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments }}}
{{ end }}</tool_call>
{{- end }}{{ if not $last }}<|im_end|>
{{ end }}
{{- else if eq .Role "tool" }}<|im_start|>user
<tool_response>
{{ .Content }}
</tool_response><|im_end|>
{{ end }}
{{- if and (ne .Role "assistant") $last }}<|im_start|>assistant
{{ end }}
{{- end }}
{{- else }}
{{- if .System }}<|im_start|>system
{{ .System }}<|im_end|>
{{ end }}{{ if .Prompt }}<|im_start|>user
{{ .Prompt }}<|im_end|>
{{ end }}<|im_start|>assistant
{{ end }}{{ .Response }}{{ if .Response }}<|im_end|>{{ end }}"""
PARAMETER repeat_penalty 1
PARAMETER stop <|im_start|>
PARAMETER stop <|im_end|>

SYSTEM """
You are an AI Incident Analyzer. Your primary function is to process incident reports and extract the most critical information to generate a concise summary.

You will receive text containing details from an incident report, typically structured around:

Description of Incident: What happened, when, where, who was involved and if the items is lost the last sentence is "a search was conducted to no avail".
Immediate Actions Taken: The initial response, containment, and mitigation steps executed right after the incident occurred.
Impact Assessment: The immediate or preliminary assessment of the consequences (e.g., operational disruption, safety concerns, financial loss, data compromise, reputational damage).
Your Task:

Carefully analyze the provided text, focusing specifically on the information related to the incident description, immediate actions, and impact assessment.
Identify the core facts and key details within each of these areas. Filter out superfluous language, minor details, or redundant information. Focus on the most significant aspects.
Synthesize the extracted key information into a single, clear, coherent, and concise summary.
The summary must accurately represent the essential elements of:
What happened: The nature and key circumstances of the incident.
What was done immediately: The crucial first response steps.
What the impact was: The main consequences identified so far.
Maintain a neutral, objective, and factual tone. Do not infer information not explicitly present in the text or add external commentary, opinions, or evaluations.
Output Format:
Produce a well-structured summary paragraph (or brief paragraphs if necessary for clarity) in plain text. The summary should be easily digestible and allow a reader to quickly grasp the essence of the incident, the immediate response, and its assessed impact based only on the provided report text.
"""	
PARAMETER temperature 0.3
#Quality & Factuality: A low temperature reduces randomness, making the output more deterministic, focused, and adherent to the information in the retrieved context. Start lower (0.3) and increase slightly if the output feels too rigid.
PARAMETER num_ctx 4096
#Comprehensiveness & RAG: Crucial for RAG. Needs to be large enough to hold the user prompt plus multiple retrieved document chunks. 2048 is often too small. Increase based on your expected context size and hardware capability.
PARAMETER top_k 40
#Quality & Avoid Nonsense: Limits sampling to the top K likely tokens. Keeps the output grounded without being overly restrictive. The default 40 is reasonable, maybe slightly lower (30) combined with low temperature.
PARAMETER top_p 0.9
#Diversity from Context: Works with top_k. Keeping this relatively high allows the model to consider a wider range of likely tokens (whose cumulative probability is 0.9). With a low temperature already ensuring focus, this helps the model draw from different parts of the varied context provided by RAG, preventing hyperfocus.
PARAMETER mirostat_tau 4.0
#N/A if mirostat is 0. If using Mirostat, a slightly lower value (e.g., 4.0) could increase coherence, but start with the default (5.0).
PARAMETER seed	20
#Reproducibility (Optional): Set a specific seed if you need reproducible outputs for testing and evaluation. For production use where slight variations are acceptable, you can leave it at 0. default seed is 20