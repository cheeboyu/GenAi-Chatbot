{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d20b48-6fb5-4285-ad1b-17a40b05a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f257274-0baa-4ee6-b48e-00a4dd2830de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c28a4b-13fb-4c9b-b6ad-0c246f4be4c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\htsocadmin\\AppData\\Local\\Temp\\ipykernel_8312\\197785862.py:22: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_model = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
      "C:\\Users\\htsocadmin\\AppData\\Local\\Temp\\ipykernel_8312\\197785862.py:23: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=LLM_MODEL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector database at ./test1/chroma_db\n",
      "Error creating vector database: Error loading firstaid.txt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vector_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m         exit()\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# --- QA Chain Setup ---\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_db\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: RETRIEVER_K})\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# --- Prompts (Adjust based on chosen CHAIN_TYPE) ---\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Example for 'stuff' chain type (uses a default prompt or you can specify one)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Setup for 'map_reduce' (if you stick with it after reducing K)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m map_prompt_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124mUse the following context to answer the question. Answer concisely based only on the provided text.\u001b[39m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124mContext: \u001b[39m\u001b[38;5;132;01m{context}\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_db' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_PATH = \"firstaid.txt\"\n",
    "PERSIST_DIRECTORY = \"./test1/chroma_db\"\n",
    "EMBEDDING_MODEL = \"bge-m3:latest\"\n",
    "LLM_MODEL = \"docbot:v1\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "RETRIEVER_K = 10  # Reduced K value significantly\n",
    "CHAIN_TYPE = \"stuff\" # Consider starting with 'stuff' if context allows with smaller K\n",
    "\n",
    "# --- Embedding and LLM Setup ---\n",
    "embedding_model = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "llm = Ollama(model=LLM_MODEL)\n",
    "\n",
    "# --- Vector Database ---\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    print(f\"Creating new vector database at {PERSIST_DIRECTORY}\")\n",
    "    try:\n",
    "        # 1. Load and prepare data\n",
    "        loader = TextLoader(DATA_PATH)\n",
    "        documents = loader.load()\n",
    "        if not documents:\n",
    "            print(f\"Error: No documents loaded from {DATA_PATH}\")\n",
    "            exit()\n",
    "\n",
    "        # 2. Split text into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=CHUNK_SIZE,\n",
    "            chunk_overlap=CHUNK_OVERLAP\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        if not chunks:\n",
    "            print(f\"Error: No chunks created from documents.\")\n",
    "            exit()\n",
    "\n",
    "        # 3. Create and persist vector database\n",
    "        print(f\"Creating Chroma DB with {len(chunks)} chunks...\")\n",
    "        vector_db = Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=PERSIST_DIRECTORY\n",
    "        )\n",
    "        print(\"Database created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector database: {e}\")\n",
    "        exit()\n",
    "else:\n",
    "    print(f\"Loading existing vector database from {PERSIST_DIRECTORY}\")\n",
    "    try:\n",
    "        vector_db = Chroma(\n",
    "            persist_directory=PERSIST_DIRECTORY,\n",
    "            embedding_function=embedding_model\n",
    "        )\n",
    "        print(\"Database loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading vector database: {e}\")\n",
    "        exit()\n",
    "\n",
    "# --- QA Chain Setup ---\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": RETRIEVER_K})\n",
    "\n",
    "# --- Prompts (Adjust based on chosen CHAIN_TYPE) ---\n",
    "\n",
    "# Example for 'stuff' chain type (uses a default prompt or you can specify one)\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\", # Simpler chain type if context fits\n",
    "#     retriever=retriever,\n",
    "#     return_source_documents=True\n",
    "# )\n",
    "\n",
    "# Setup for 'map_reduce' (if you stick with it after reducing K)\n",
    "map_prompt_template = \"\"\"\n",
    "Use the following context to answer the question. Answer concisely based only on the provided text.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "MAP_PROMPT = PromptTemplate(\n",
    "    template=map_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "reduce_prompt_template = \"\"\"\n",
    "Synthesize the following individual answers into a single, coherent, and comprehensive final answer based only on the provided documents. Avoid repetition.\n",
    "Summaries: {summaries}\n",
    "Final Answer:\"\"\"\n",
    "REDUCE_PROMPT = PromptTemplate(\n",
    "    template=reduce_prompt_template,\n",
    "    input_variables=[\"summaries\"]\n",
    ")\n",
    "\n",
    "# Check if selected chain type requires specific prompts\n",
    "if CHAIN_TYPE == \"map_reduce\":\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"map_reduce\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\n",
    "            \"question_prompt\": MAP_PROMPT,\n",
    "            \"combine_prompt\": REDUCE_PROMPT,\n",
    "            # Langchain map_reduce uses 'summaries' by default for the combine_prompt input\n",
    "            # Explicitly setting combine_document_variable_name might not always be needed\n",
    "            # if your REDUCE_PROMPT variable matches the default ('summaries').\n",
    "            # Let's keep it for clarity as you had it:\n",
    "            \"combine_document_variable_name\": \"summaries\"\n",
    "        },\n",
    "        return_source_documents=True\n",
    "    )\n",
    "elif CHAIN_TYPE == \"stuff\":\n",
    "     # Example using a custom prompt for 'stuff'\n",
    "     stuff_template = \"\"\"Use the following pieces of context from the document as reference to answer the question at the end as accurately as possible. Do not summarise content from the document, give the document content as is then, provide a summary.If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "     {context}\n",
    "\n",
    "     Question: {question}\n",
    "     Helpful Answer:\"\"\"\n",
    "     STUFF_PROMPT = PromptTemplate(template=stuff_template, input_variables=[\"context\", \"question\"])\n",
    "     qa_chain = RetrievalQA.from_chain_type(\n",
    "         llm=llm,\n",
    "         chain_type=\"stuff\",\n",
    "         retriever=retriever,\n",
    "         chain_type_kwargs={\"prompt\": STUFF_PROMPT},\n",
    "         return_source_documents=True\n",
    "     )\n",
    "# Add other chain types (refine, map_rerank) here if needed\n",
    "else:\n",
    "    print(f\"Error: Unsupported chain type '{CHAIN_TYPE}'\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Query Loop ---\n",
    "print(f\"\\nQA System Initialized (Using Chain Type: '{CHAIN_TYPE}', Retriever k={RETRIEVER_K}).\")\n",
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit'): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    if not query:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Use invoke for LangChain Expression Language (LCEL) compatibility\n",
    "        result = qa_chain.invoke({\"query\": query}) # Pass query in a dictionary for standard LCEL format\n",
    "\n",
    "        print(\"\\nAnswer:\", result.get(\"result\", \"No answer found.\"))\n",
    "\n",
    "        source_docs = result.get(\"source_documents\", [])\n",
    "        if source_docs:\n",
    "            # Get unique source filenames\n",
    "            source_files = list(set(doc.metadata.get('source', 'Unknown Source') for doc in source_docs))\n",
    "            print(\"Sources:\", \", \".join(source_files))\n",
    "        else:\n",
    "            print(\"Sources: No source documents found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during query processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbc807-1841-4a21-8c48-66e6589ee6c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\htsocadmin\\AppData\\Local\\Temp\\ipykernel_3276\\1715025299.py:23: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=LLM_MODEL)\n",
      "C:\\Users\\htsocadmin\\AppData\\Local\\Temp\\ipykernel_3276\\1715025299.py:60: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector database from ./test1/chroma_db\n",
      "Database loaded successfully.\n",
      "\n",
      "QA System Initialized (Using Chain Type: 'stuff', Retriever k=10).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit'):  what is inside the document\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: <think>\n",
      "Okay, the user is asking what's inside the document based on the provided context. Let me check the context given. The only excerpts provided are \"We are HTSOC\" repeated twice. There's no other information in the document excerpts. The user wants an answer using only the document content. Since the document only mentions \"We are HTSOC\" and nothing else, the answer should reflect that. I need to state that the document contains just those two lines. Also, the user mentioned not to summarize but to provide the document content as is. So I should present the excerpts exactly as they are and then summarize that the document only includes those statements. No other information is present, so the answer is straightforward.\n",
      "</think>\n",
      "\n",
      "The document excerpts provided contain only the following text:  \n",
      "**\"We are HTSOC\"**  \n",
      "**\"We are HTSOC\"**  \n",
      "\n",
      "No additional content or context is included in the provided excerpts.\n",
      "Sources: C:/Users/htsocadmin/Desktop/test.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_PATH = \"C:/Users/htsocadmin/Desktop/text.txt\"\n",
    "PERSIST_DIRECTORY = \"./test1/chroma_db\"\n",
    "EMBEDDING_MODEL = \"bge-m3:latest\"\n",
    "LLM_MODEL = \"docbot:v1\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "RETRIEVER_K = 10  # Reduced K value significantly\n",
    "CHAIN_TYPE = \"stuff\" # Consider starting with 'stuff' if context allows with smaller K\n",
    "\n",
    "# --- Embedding and LLM Setup ---\n",
    "embedding_model = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "llm = Ollama(model=LLM_MODEL)\n",
    "\n",
    "# --- Vector Database ---\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    print(f\"Creating new vector database at {PERSIST_DIRECTORY}\")\n",
    "    try:\n",
    "        # 1. Load and prepare data\n",
    "        loader = TextLoader(DATA_PATH)\n",
    "        documents = loader.load()\n",
    "        if not documents:\n",
    "            print(f\"Error: No documents loaded from {DATA_PATH}\")\n",
    "            exit()\n",
    "\n",
    "        # 2. Split text into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=CHUNK_SIZE,\n",
    "            chunk_overlap=CHUNK_OVERLAP\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        if not chunks:\n",
    "            print(f\"Error: No chunks created from documents.\")\n",
    "            exit()\n",
    "\n",
    "        # 3. Create and persist vector database\n",
    "        print(f\"Creating Chroma DB with {len(chunks)} chunks...\")\n",
    "        vector_db = Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=PERSIST_DIRECTORY\n",
    "        )\n",
    "        print(\"Database created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector database: {e}\")\n",
    "        exit()\n",
    "else:\n",
    "    print(f\"Loading existing vector database from {PERSIST_DIRECTORY}\")\n",
    "    try:\n",
    "        vector_db = Chroma(\n",
    "            persist_directory=PERSIST_DIRECTORY,\n",
    "            embedding_function=embedding_model\n",
    "        )\n",
    "        print(\"Database loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading vector database: {e}\")\n",
    "        exit()\n",
    "\n",
    "# --- QA Chain Setup ---\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": RETRIEVER_K})\n",
    "\n",
    "# --- Prompts (Adjust based on chosen CHAIN_TYPE) ---\n",
    "\n",
    "# Example for 'stuff' chain type (uses a default prompt or you can specify one)\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\", # Simpler chain type if context fits\n",
    "#     retriever=retriever,\n",
    "#     return_source_documents=True\n",
    "# )\n",
    "\n",
    "# Setup for 'map_reduce' (if you stick with it after reducing K)\n",
    "map_prompt_template = \"\"\"\n",
    "Use the following context to answer the question. Answer concisely based only on the provided text.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "MAP_PROMPT = PromptTemplate(\n",
    "    template=map_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "reduce_prompt_template = \"\"\"\n",
    "Synthesize the following individual answers into a single, coherent, and comprehensive final answer based only on the provided documents. Avoid repetition.\n",
    "Summaries: {summaries}\n",
    "Final Answer:\"\"\"\n",
    "REDUCE_PROMPT = PromptTemplate(\n",
    "    template=reduce_prompt_template,\n",
    "    input_variables=[\"summaries\"]\n",
    ")\n",
    "\n",
    "# Check if selected chain type requires specific prompts\n",
    "if CHAIN_TYPE == \"map_reduce\":\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"map_reduce\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\n",
    "            \"question_prompt\": MAP_PROMPT,\n",
    "            \"combine_prompt\": REDUCE_PROMPT,\n",
    "            # Langchain map_reduce uses 'summaries' by default for the combine_prompt input\n",
    "            # Explicitly setting combine_document_variable_name might not always be needed\n",
    "            # if your REDUCE_PROMPT variable matches the default ('summaries').\n",
    "            # Let's keep it for clarity as you had it:\n",
    "            \"combine_document_variable_name\": \"summaries\"\n",
    "        },\n",
    "        return_source_documents=True\n",
    "    )\n",
    "elif CHAIN_TYPE == \"stuff\":\n",
    "     # Example using a custom prompt for 'stuff'\n",
    "     stuff_template = \"\"\"Use the following pieces of context from the document as reference to answer the question at the end as accurately as possible. Do not summarise content from the document, give the document content as is then, provide a summary.If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "     {context}\n",
    "\n",
    "     Question: {question}\n",
    "     Helpful Answer:\"\"\"\n",
    "     STUFF_PROMPT = PromptTemplate(template=stuff_template, input_variables=[\"context\", \"question\"])\n",
    "     qa_chain = RetrievalQA.from_chain_type(\n",
    "         llm=llm,\n",
    "         chain_type=\"stuff\",\n",
    "         retriever=retriever,\n",
    "         chain_type_kwargs={\"prompt\": STUFF_PROMPT},\n",
    "         return_source_documents=True\n",
    "     )\n",
    "# Add other chain types (refine, map_rerank) here if needed\n",
    "else:\n",
    "    print(f\"Error: Unsupported chain type '{CHAIN_TYPE}'\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Query Loop ---\n",
    "print(f\"\\nQA System Initialized (Using Chain Type: '{CHAIN_TYPE}', Retriever k={RETRIEVER_K}).\")\n",
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit'): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    if not query:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Use invoke for LangChain Expression Language (LCEL) compatibility\n",
    "        result = qa_chain.invoke({\"query\": query}) # Pass query in a dictionary for standard LCEL format\n",
    "\n",
    "        print(\"\\nAnswer:\", result.get(\"result\", \"No answer found.\"))\n",
    "\n",
    "        source_docs = result.get(\"source_documents\", [])\n",
    "        if source_docs:\n",
    "            # Get unique source filenames\n",
    "            source_files = list(set(doc.metadata.get('source', 'Unknown Source') for doc in source_docs))\n",
    "            print(\"Sources:\", \", \".join(source_files))\n",
    "        else:\n",
    "            print(\"Sources: No source documents found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during query processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f0d7f-a690-4533-af8c-030c20542780",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eca3c3-ba7a-47a2-8f7c-3b9685f5c7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e09984-e0ff-482b-9ce2-6cb6ac1306f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51082f6-8c8e-4a29-807b-13a6932a86f5",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: ':class:`~langchain-ollama': Expected package name at the start of dependency specifier\n",
      "    :class:`~langchain-ollama\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "!pip install -U :class:`~langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ebdf21-142c-4aa6-a9b6-3a1305ac664b",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LibMambaUnsatisfiableError: Encountered problems while solving:\n",
      "  - nothing provides python >=3.4,<3.5.0a0 needed by conda-4.3.29-py34h479681e_0\n",
      "\n",
      "Could not solve for environment specs\n",
      "The following packages are incompatible\n",
      "\\u251c\\u2500 anaconda_prompt is installable with the potential options\n",
      "\\u2502  \\u251c\\u2500 anaconda_prompt 1.1.0 would require\n",
      "\\u2502  \\u2502  \\u2514\\u2500 menuinst >=2.1.1 , which can be installed;\n",
      "\\u2502  \\u2514\\u2500 anaconda_prompt 1.0.0 would require\n",
      "\\u2502     \\u2514\\u2500 menuinst >=2.1.0 , which can be installed;\n",
      "\\u251c\\u2500 conda-token is installable with the potential options\n",
      "\\u2502  \\u251c\\u2500 conda-token [0.5.0|0.6.0] would require\n",
      "\\u2502  \\u2502  \\u2514\\u2500 conda >=4.6,!=23.10.0,!=23.11.0  with the potential options\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [24.1.0|24.1.1|...|25.3.1] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 python >=3.12,<3.13.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.14.0] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 python >=3.10,<3.11.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.9.2] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 python >=3.7,<3.8.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.9.2] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 python >=3.8,<3.9.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.9.2] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 python >=3.9,<3.10.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [22.11.1|23.1.0|...|23.9.0] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 menuinst >=1.4.11,<2  with the potential options\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 menuinst [1.4.11|1.4.12|1.4.13|1.4.14|1.4.16] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=2.7,<2.8.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 menuinst [1.4.11|1.4.12|1.4.13|1.4.14] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.5,<3.6.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 menuinst [1.4.11|1.4.12|...|1.4.18] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.6,<3.7.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 menuinst [1.4.11|1.4.13|...|1.4.19] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.7,<3.8.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 menuinst [1.4.16|1.4.17|1.4.18|1.4.19] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.8,<3.9.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 menuinst [1.4.16|1.4.17|1.4.18|1.4.19] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.9,<3.10.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 menuinst [1.4.17|1.4.19] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.10,<3.11.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2514\\u2500 menuinst 1.4.19 conflicts with any installable versions previously reported;\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [24.1.0|24.1.1|...|24.9.2] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 conda-libmamba-solver >=23.11.0  with the potential options\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 conda-libmamba-solver [24.11.1|25.1.0|25.1.1|25.3.0|25.4.0] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 libmambapy >=2  with the potential options\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 2.0.5 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.10,<3.11.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy [1.5.11|1.5.8|2.0.5] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 libmamba 2.0.5 hcd6fe79_1, which requires\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2502  \\u2514\\u2500 openssl >=3.0.15,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 openssl >=3.0.15,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 2.0.5 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.12,<3.13.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 2.0.5 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python_abi 3.13.* *_cp313, which requires\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502     \\u2514\\u2500 python 3.13.* *_cp313, which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2514\\u2500 libmambapy 2.0.5 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502        \\u2514\\u2500 python >=3.9,<3.10.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 conda-libmamba-solver [24.1.0|24.7.0|24.9.0] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 libmambapy [>=1.5.6,<2.0.0a0 |>=1.5.6,<2.0a0 ] with the potential options\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy [1.5.11|1.5.8|2.0.5], which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 openssl >=3.0.12,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.10,<3.11.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 openssl >=3.0.12,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 libmamba 1.5.6 h99b1521_0, which does not exist (perhaps a missing channel);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 openssl >=3.0.12,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.8,<3.9.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 openssl >=3.0.12,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.9,<3.10.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2514\\u2500 libmambapy 1.5.8 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502        \\u2514\\u2500 openssl >=3.0.13,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 conda-libmamba-solver [23.11.0|23.11.1|23.12.0] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.10,<3.11.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 conda-libmamba-solver [23.11.0|23.11.1|23.12.0] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 libmambapy >=1.5.3,<2.0.0a0  with the potential options\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy [1.5.11|1.5.8|2.0.5], which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.3 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 openssl >=3.0.11,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.10,<3.11.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.3 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 openssl >=3.0.11,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.3 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 openssl >=3.0.12,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.12,<3.13.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.3 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 openssl >=3.0.11,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.8,<3.9.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.3 would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u251c\\u2500 openssl >=3.0.11,<4.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.9,<3.10.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6, which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6, which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6, which cannot be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6, which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u251c\\u2500 libmambapy 1.5.6, which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u2502     \\u2514\\u2500 libmambapy 1.5.8, which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u2502     \\u251c\\u2500 conda-libmamba-solver [23.11.0|23.11.1|23.12.0] would require\n",
      "\\u2502  \\u2502     \\u2502     \\u2502  \\u2514\\u2500 python >=3.8,<3.9.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2502     \\u2514\\u2500 conda-libmamba-solver [23.11.0|23.11.1|23.12.0] would require\n",
      "\\u2502  \\u2502     \\u2502        \\u2514\\u2500 python >=3.9,<3.10.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [25.1.0|25.1.1|25.3.0|25.3.1] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 conda-libmamba-solver >=24.11.0 , which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [25.3.0|25.3.1] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 python_abi 3.13.* *_cp313, which can be installed (as previously explained);\n",
      "\\u2502  \\u2502     \\u251c\\u2500 conda [4.10.0|4.10.1|...|4.9.2] would require\n",
      "\\u2502  \\u2502     \\u2502  \\u2514\\u2500 python >=3.6,<3.7.0a0 , which can be installed;\n",
      "\\u2502  \\u2502     \\u2514\\u2500 conda [4.3.27|4.3.29|...|4.8.3] would require\n",
      "\\u2502  \\u2502        \\u2514\\u2500 python >=2.7,<2.8.0a0 , which can be installed;\n",
      "\\u2502  \\u2514\\u2500 conda-token [0.1.2|0.1.3|0.2.0|0.3.0|0.4.0] would require\n",
      "\\u2502     \\u2514\\u2500 conda >=4.3,<23.9  with the potential options\n",
      "\\u2502        \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.14.0], which can be installed (as previously explained);\n",
      "\\u2502        \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.9.2], which can be installed (as previously explained);\n",
      "\\u2502        \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.9.2], which can be installed (as previously explained);\n",
      "\\u2502        \\u251c\\u2500 conda [22.11.0|22.11.1|...|4.9.2], which can be installed (as previously explained);\n",
      "\\u2502        \\u251c\\u2500 conda [22.11.1|23.1.0|...|23.9.0], which can be installed (as previously explained);\n",
      "\\u2502        \\u251c\\u2500 conda [4.10.0|4.10.1|...|4.9.2], which can be installed (as previously explained);\n",
      "\\u2502        \\u251c\\u2500 conda [4.3.27|4.3.29|...|4.8.3], which can be installed (as previously explained);\n",
      "\\u2502        \\u251c\\u2500 conda [4.3.27|4.3.29|...|4.5.9] would require\n",
      "\\u2502        \\u2502  \\u2514\\u2500 python >=3.5,<3.6.0a0 , which can be installed;\n",
      "\\u2502        \\u2514\\u2500 conda [4.3.29|4.3.30] would require\n",
      "\\u2502           \\u2514\\u2500 python >=3.4,<3.5.0a0 , which does not exist (perhaps a missing channel);\n",
      "\\u2514\\u2500 python 3.11.2**  is not installable because it requires\n",
      "   \\u2514\\u2500 openssl >=1.1.1t,<1.1.2a , which conflicts with any installable versions previously reported.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install python=3.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a65d3b-3b9b-40e4-b9cb-7ec16589c54f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.56 (from langchain_community)\n",
      "  Using cached langchain_core-0.3.56-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.24 (from langchain_community)\n",
      "  Using cached langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_community) (2.6.1)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain_community)\n",
      "  Downloading langsmith-0.3.38-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.24->langchain_community)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.24->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain_community) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.5 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 5.0 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.56-py3-none-any.whl (437 kB)\n",
      "Downloading langsmith-0.3.38-py3-none-any.whl (359 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, orjson, marshmallow, httpx-sse, dataclasses-json, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.24 langchain-core-0.3.56 langchain-text-splitters-0.3.8 langchain_community-0.3.23 langsmith-0.3.38 marshmallow-3.26.1 orjson-3.10.16 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d77011e-e0a2-4b40-951a-f253e3f9ed10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain) (0.3.56)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain) (0.3.38)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08fd5db0-447a-4074-bb23-6be17a8b4119",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain_text_splitters) (0.3.56)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.3.38)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.11.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain_text_splitters) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured\n",
    "!pip install langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3219c6-8b20-415a-99db-2463cd9cd8c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.7-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (2.11.3)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-4.0.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (4.13.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.21.1-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Using cached starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-1.0.5-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Using cached chromadb-1.0.7-cp39-abi3-win_amd64.whl (18.3 MB)\n",
      "Using cached fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "Using cached mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached onnxruntime-1.21.1-cp312-cp312-win_amd64.whl (12.3 MB)\n",
      "Using cached opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
      "Using cached opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
      "Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
      "Using cached posthog-4.0.0-py2.py3-none-any.whl (92 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Using cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Using cached watchfiles-1.0.5-cp312-cp312-win_amd64.whl (291 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: chroma-hnswlib\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.6-cp312-cp312-win_amd64.whl size=160109 sha256=a4e23b4bf370eeed8146011678e955917fe72d5b9e817d9eb6f9bfb84889b068\n",
      "  Stored in directory: c:\\users\\htsocadmin\\appdata\\local\\pip\\cache\\wheels\\28\\29\\0e\\934c768c2e673547ec6e947e821346f4ed691a089fe046743f\n",
      "Successfully built chroma-hnswlib\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, websockets, rsa, pyreadline3, pyproject_hooks, protobuf, opentelemetry-util-http, oauthlib, mmh3, importlib-resources, httptools, grpcio, deprecated, chroma-hnswlib, bcrypt, asgiref, watchfiles, uvicorn, starlette, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, humanfriendly, huggingface-hub, googleapis-common-protos, google-auth, build, tokenizers, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, fastapi, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed asgiref-3.8.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.7 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.9 flatbuffers-25.2.10 google-auth-2.39.0 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 huggingface-hub-0.30.2 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-4.0.0 protobuf-5.29.4 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rsa-4.9.1 starlette-0.45.3 tokenizers-0.21.1 uvicorn-0.34.2 watchfiles-1.0.5 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c1f126-b89c-4056-b275-9e00cc7fab78",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.4.8-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from ollama) (2.11.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\htsocadmin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
      "Using cached ollama-0.4.8-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.4.8\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2eee52c-3424-466e-952d-95984521f53a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading firstaid.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:43\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 43\u001b[0m         text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8f in position 2794: character maps to <undefined>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 1. Load and prepare data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loader \u001b[38;5;241m=\u001b[39m TextLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirstaid.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2. Split text into chunks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m     19\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     20\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:56\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error loading firstaid.txt"
     ]
    }
   ],
   "source": [
    "# Required installations:\n",
    "# pip install langchain ollama chromadb PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 1. Load and prepare data\n",
    "#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\n",
    "loader = TextLoader(\"firstaid.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Create vector database with Ollama embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")  # [[8]]\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./test1/chroma_db\"  # Saves the vector store locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a349e2f0-1b84-4598-8b8b-e425cd943ee9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading C:/Users/htsocadmin/Desktop/project folder/firstaid.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:43\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 43\u001b[0m         text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8f in position 2794: character maps to <undefined>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 1. Load and prepare data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loader \u001b[38;5;241m=\u001b[39m TextLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/htsocadmin/Desktop/project folder/firstaid.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2. Split text into chunks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m     19\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     20\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:56\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error loading C:/Users/htsocadmin/Desktop/project folder/firstaid.txt"
     ]
    }
   ],
   "source": [
    "# Required installations:\n",
    "# pip install langchain ollama chromadb PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 1. Load and prepare data\n",
    "#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\n",
    "loader = TextLoader(\"C:/Users/htsocadmin/Desktop/project folder/firstaid.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Create vector database with Ollama embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")  # [[8]]\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./test1/chroma_db\"  # Saves the vector store locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2042ce1b-742c-415b-8cbb-ed477ca07bb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading C:/Users/htsocadmin/Desktop/firstaid.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:43\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 43\u001b[0m         text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8f in position 2794: character maps to <undefined>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 1. Load and prepare data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loader \u001b[38;5;241m=\u001b[39m TextLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/htsocadmin/Desktop/firstaid.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2. Split text into chunks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m     19\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     20\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:56\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error loading C:/Users/htsocadmin/Desktop/firstaid.txt"
     ]
    }
   ],
   "source": [
    "# Required installations:\n",
    "# pip install langchain ollama chromadb PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 1. Load and prepare data\n",
    "#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\n",
    "loader = TextLoader(\"C:/Users/htsocadmin/Desktop/firstaid.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Create vector database with Ollama embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")  # [[8]]\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./test1/chroma_db\"  # Saves the vector store locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b434c3-01eb-4161-8e9c-b73274410c95",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "incomplete escape \\U at position 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate conda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:30\u001b[0m, in \u001b[0;36mis_conda_environment.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:128\u001b[0m, in \u001b[0;36mPackagingMagics.conda\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;129m@line_magic\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;129m@is_conda_environment\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconda\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the conda package manager within the current kernel.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Usage:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m      %conda install [pkgs]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     conda \u001b[38;5;241m=\u001b[39m _get_conda_like_executable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_command(conda, line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:53\u001b[0m, in \u001b[0;36m_get_conda_like_executable\u001b[1;34m(command)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Otherwise, attempt to extract the executable from conda history.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# This applies in any conda environment.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m history \u001b[38;5;241m=\u001b[39m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^#\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*cmd:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(?P<command>.*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms[create|install]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     history,\n\u001b[0;32m     56\u001b[0m     flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mMULTILINE,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroupdict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:177\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:307\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 307\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:979\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    976\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 979\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    980\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    461\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:862\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    859\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    860\u001b[0m sub_verbose \u001b[38;5;241m=\u001b[39m ((verbose \u001b[38;5;129;01mor\u001b[39;00m (add_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    861\u001b[0m                \u001b[38;5;129;01mnot\u001b[39;00m (del_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[1;32m--> 862\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m source\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing ), unterminated subpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    461\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:544\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 544\u001b[0m     code \u001b[38;5;241m=\u001b[39m _escape(source, this, state)\n\u001b[0;32m    545\u001b[0m     subpatternappend(code)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPECIAL_CHARS:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:398\u001b[0m, in \u001b[0;36m_escape\u001b[1;34m(source, escape, state)\u001b[0m\n\u001b[0;32m    396\u001b[0m escape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mgetwhile(\u001b[38;5;241m8\u001b[39m, HEXDIGITS)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincomplete escape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m escape, \u001b[38;5;28mlen\u001b[39m(escape))\n\u001b[0;32m    399\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(escape[\u001b[38;5;241m2\u001b[39m:], \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28mchr\u001b[39m(c) \u001b[38;5;66;03m# raise ValueError for invalid code\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: incomplete escape \\U at position 28"
     ]
    }
   ],
   "source": [
    "conda update conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df18e98-b57b-415a-b357-accc02d7f46a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading test.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:42\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     43\u001b[0m         text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.txt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 1. Load and prepare data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loader \u001b[38;5;241m=\u001b[39m TextLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 2. Split text into chunks\u001b[39;00m\n\u001b[0;32m     18\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m     19\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     20\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:58\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     60\u001b[0m metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)}\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m Document(page_content\u001b[38;5;241m=\u001b[39mtext, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error loading test.txt"
     ]
    }
   ],
   "source": [
    "# Required installations:\n",
    "# pip install langchain ollama chromadb PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 1. Load and prepare data\n",
    "#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\n",
    "loader = TextLoader(\"test.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Create vector database with Ollama embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")  # [[8]]\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./test1/chroma_db\"  # Saves the vector store locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1da3927-7bba-47c3-9532-261923655abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\htsocadmin\\AppData\\Local\\Temp\\ipykernel_3276\\3574283797.py:25: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")  # [[8]]\n"
     ]
    }
   ],
   "source": [
    "# Required installations:\n",
    "# pip install langchain ollama chromadb PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 1. Load and prepare data\n",
    "#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\n",
    "loader = TextLoader(\"C:/Users/htsocadmin/Desktop/test.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Create vector database with Ollama embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")  # [[8]]\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./test1/chroma_db\"  # Saves the vector store locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1aec26-1091-43af-8c3f-5b03fc678af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required installations:\n",
    "# pip install langchain ollama chromadb PyPDFLoader\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 1. Load and prepare data\n",
    "#loader = PyPDFLoader(\"cybersecurity_threats.pdf\")  # Replace with your PDF path\n",
    "loader = TextLoader(\"C:/Users/htsocadmin/Desktop/test.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Create vector database with Ollama embeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3:latest\")  # [[8]]\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./test1/chroma_db\"  # Saves the vector store locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bcd2a-c0b1-4512-ae5b-803b3eb6589a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2ccdc-e2b1-487d-bf70-dbda2ad2ebb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
